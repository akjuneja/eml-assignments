{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9ed6b54-f74e-4341-bf36-10d5cc01a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b95bf1",
   "metadata": {},
   "source": [
    "### 1. Phoneme Dataset\n",
    "Load the phoneme dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21c9a895-9863-4a10-9c4b-fcc5dcb21283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      row.names       x.1       x.2       x.3       x.4       x.5       x.6  \\\n",
      "0             1   9.85770   9.20711   9.81689   9.01692   9.05675   8.92518   \n",
      "1             2  13.23079  14.19189  15.34428  18.11737  19.53875  18.32726   \n",
      "2             3  10.81889   9.07615   9.77940  12.20135  12.59005  10.53364   \n",
      "3             4  10.53679   9.12147  10.84621  13.92331  13.52476  10.27831   \n",
      "4             5  12.96705  13.69454  14.91182  18.22292  18.45390  17.25760   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "4504       4505  11.38394  10.21040  16.32658  18.30125  16.91804  10.90029   \n",
      "4505       4506  12.01774  11.86761  16.34707  18.05214  15.97599  12.86022   \n",
      "4506       4507  12.30174  12.40383   9.06497  12.43750  13.48388  13.52034   \n",
      "4507       4508   8.39388   9.84770  16.24534  17.35311  14.80537  12.72429   \n",
      "4508       4509   8.14032   9.93753  16.30187  17.31425  14.40116  13.52353   \n",
      "\n",
      "           x.7       x.8       x.9  ...     x.249     x.250     x.251  \\\n",
      "0     11.28308  11.52980  10.79713  ...  12.68076  11.20767  13.69394   \n",
      "1     17.34169  17.16861  19.63557  ...   8.45714   8.77266   9.59717   \n",
      "2      8.54693   9.46049  11.96755  ...   5.00824   5.51019   5.95725   \n",
      "3      8.97459  11.57109  12.35839  ...   5.85688   5.40324   6.07126   \n",
      "4     17.79614  17.76387  18.99632  ...   8.00151   7.58624   6.65202   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "4504  17.10393  19.37741  18.46994  ...   9.79996   7.85765   6.92906   \n",
      "4505  16.83436  18.38985  15.90410  ...   8.20094   8.40645   7.49869   \n",
      "4506  12.97796  11.58782  12.54174  ...  12.83836  10.62525  10.15274   \n",
      "4507  17.01145  17.54733  14.35809  ...   4.57875   7.91262   8.08014   \n",
      "4508  16.85938  17.14016  13.06426  ...   5.27574   6.95050   7.83462   \n",
      "\n",
      "         x.252     x.253     x.254     x.255     x.256    g  \\\n",
      "0     13.72055  12.16628  12.92489  12.51195   9.75527   sh   \n",
      "1      8.45336   7.57730   5.38504   9.43063   8.59328   iy   \n",
      "2      7.04992   7.02469   6.58416   6.27058   3.85042  dcl   \n",
      "3      5.30651   4.27412   3.63384   3.22823   4.63123  dcl   \n",
      "4      7.69109   6.93683   7.03600   7.01278   8.52197   aa   \n",
      "...        ...       ...       ...       ...       ...  ...   \n",
      "4504   8.89384   8.04072   6.99793   6.07412   7.32593   iy   \n",
      "4505   9.56486  10.86934   8.85308   9.88492   6.35767   aa   \n",
      "4506   9.59347  10.66338   9.88007  10.82203  12.00199   sh   \n",
      "4507   9.25111   9.56086   9.37979   6.83916   8.54817   ao   \n",
      "4508   7.96455   7.26886   7.08945   7.72929   6.42167   ao   \n",
      "\n",
      "                  speaker  \n",
      "0     train.dr1.mcpm0.sa1  \n",
      "1     train.dr1.mcpm0.sa1  \n",
      "2     train.dr1.mcpm0.sa1  \n",
      "3     train.dr1.mcpm0.sa1  \n",
      "4     train.dr1.mcpm0.sa1  \n",
      "...                   ...  \n",
      "4504   test.dr8.mslb0.sa1  \n",
      "4505   test.dr8.mslb0.sa1  \n",
      "4506   test.dr8.mslb0.sa1  \n",
      "4507   test.dr8.mslb0.sa1  \n",
      "4508   test.dr8.mslb0.sa1  \n",
      "\n",
      "[4509 rows x 259 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/phoneme.csv')\n",
    "print(data)\n",
    "\n",
    "# TODO \n",
    "# Split the dataset into a train and test dataset according to column \"speaker\".\n",
    "# Be sure to exclude row number, \"speaker\" and response columns from your features.\n",
    "train = data.loc[data.speaker.str.contains(\"train\")]\n",
    "y_train = train.loc[:,\"g\"]\n",
    "X_train = train.drop(['row.names', 'g', 'speaker'], axis=1)\n",
    "\n",
    "test = data.loc[data.speaker.str.contains(\"test\")]\n",
    "y_test = test.loc[:,\"g\"]\n",
    "X_test = test.drop(['row.names', 'g', 'speaker'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1545466-f4b8-4dac-aedc-23a28aaa34ba",
   "metadata": {},
   "source": [
    "### 2. LDA modelling\n",
    "Fit an LDA model. Compute and report the train and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c07740f4-6f7c-4f7f-9186-e808c6a1234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          aa       0.84      0.82      0.83       519\n",
      "          ao       0.88      0.89      0.88       759\n",
      "         dcl       1.00      0.98      0.99       562\n",
      "          iy       0.99      1.00      0.99       852\n",
      "          sh       1.00      1.00      1.00       648\n",
      "\n",
      "    accuracy                           0.94      3340\n",
      "   macro avg       0.94      0.94      0.94      3340\n",
      "weighted avg       0.94      0.94      0.94      3340\n",
      "\n",
      "Train error  0.05598802395209579\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          aa       0.77      0.73      0.75       176\n",
      "          ao       0.83      0.85      0.84       263\n",
      "         dcl       0.99      0.97      0.98       195\n",
      "          iy       0.98      0.99      0.99       311\n",
      "          sh       1.00      1.00      1.00       224\n",
      "\n",
      "    accuracy                           0.92      1169\n",
      "   macro avg       0.91      0.91      0.91      1169\n",
      "weighted avg       0.92      0.92      0.92      1169\n",
      "\n",
      "Test Error  0.08041060735671512\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "model_lda = lda.fit(X_train, y_train)\n",
    "\n",
    "# train error\n",
    "pred_train=model_lda.predict(X_train)\n",
    "print(classification_report(y_train, pred_train))\n",
    "print(\"Train error \", (1-np.mean(pred_train == y_train)))\n",
    "\n",
    "print(\"\\n\")\n",
    "# test error\n",
    "pred_test=model_lda.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"Test Error \", (1-np.mean(pred_test == y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2205c6e-02cf-4228-8f81-9396308ba0f7",
   "metadata": {},
   "source": [
    "### 3. LDA on different phonemes\n",
    "For every pair of phenomes select the corresponding data points. Fit an LDA model on all data sets and repeat the steps done in (2). Explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7709f18-b292-4ae3-a13e-d0424e329ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: sh vs iy\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: sh vs dcl\n",
      "Train Error: 0.0008\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: sh vs aa\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: sh vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: iy vs dcl\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0138\n",
      "\n",
      "Pair: iy vs aa\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: iy vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0017\n",
      "\n",
      "Pair: dcl vs aa\n",
      "Train Error: 0.0009\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: dcl vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: aa vs ao\n",
      "Train Error: 0.1064\n",
      "Test Error: 0.2141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "phonemes = data['g'].unique()\n",
    "\n",
    "for i in range(len(phonemes)):\n",
    "    for j in range(i + 1, len(phonemes)):\n",
    "        phoneme_1 = phonemes[i]\n",
    "        phoneme_2 = phonemes[j]\n",
    "\n",
    "        # Corresponding data points for the pair of phonemes\n",
    "        selected_indices = (data['g'] == phoneme_1) | (data['g'] == phoneme_2)\n",
    "        selected_data = data[selected_indices]\n",
    "        \n",
    "        train_selected_data = selected_data.loc[selected_data.speaker.str.contains(\"train\")]\n",
    "        test_selected_data = selected_data.loc[selected_data.speaker.str.contains(\"test\")]\n",
    "        \n",
    "        X_train_selected = train_selected_data.drop(columns=['row.names', 'speaker', 'g'])\n",
    "        y_train_selected = train_selected_data['g']\n",
    "\n",
    "        X_test_selected = test_selected_data.drop(columns=['row.names', 'speaker', 'g'])\n",
    "        y_test_selected = test_selected_data['g']\n",
    "\n",
    "        # Fit LDA model\n",
    "        lda_selected = LinearDiscriminantAnalysis()\n",
    "        lda_selected.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "        train_pred_selected = lda_selected.predict(X_train_selected)\n",
    "        test_pred_selected = lda_selected.predict(X_test_selected)\n",
    "\n",
    "        train_error_sel = 1 - accuracy_score(y_train_selected, train_pred_selected)\n",
    "        test_error_sel = 1 - accuracy_score(y_test_selected, test_pred_selected)\n",
    "\n",
    "        print(f\"Pair: {phoneme_1} vs {phoneme_2}\")\n",
    "        #print(classification_report(y_train_selected, train_pred_selected))\n",
    "        print(f\"Train Error: {train_error_sel:.4f}\")\n",
    "        #print(classification_report(y_test_selected, test_pred_selected))\n",
    "        print(f\"Test Error: {test_error_sel:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b231d3e",
   "metadata": {},
   "source": [
    "### 4. QDA\n",
    "Repeat steps (2) and (4) using QDA and report your findings. What model do you prefer and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52089486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          aa       1.00      1.00      1.00       519\n",
      "          ao       1.00      1.00      1.00       759\n",
      "         dcl       1.00      1.00      1.00       562\n",
      "          iy       1.00      1.00      1.00       852\n",
      "          sh       1.00      1.00      1.00       648\n",
      "\n",
      "    accuracy                           1.00      3340\n",
      "   macro avg       1.00      1.00      1.00      3340\n",
      "weighted avg       1.00      1.00      1.00      3340\n",
      "\n",
      "Train error  0.0\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          aa       0.93      0.15      0.26       176\n",
      "          ao       0.64      0.98      0.78       263\n",
      "         dcl       0.99      0.85      0.91       195\n",
      "          iy       0.90      1.00      0.95       311\n",
      "          sh       0.98      0.99      0.98       224\n",
      "\n",
      "    accuracy                           0.84      1169\n",
      "   macro avg       0.89      0.80      0.78      1169\n",
      "weighted avg       0.88      0.84      0.81      1169\n",
      "\n",
      "Test Error  0.1582549187339607\n",
      "\n",
      "Pair: sh vs iy\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0019\n",
      "\n",
      "Pair: sh vs dcl\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0072\n",
      "\n",
      "Pair: sh vs aa\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0200\n",
      "\n",
      "Pair: sh vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0021\n",
      "\n",
      "Pair: iy vs dcl\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0593\n",
      "\n",
      "Pair: iy vs aa\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0185\n",
      "\n",
      "Pair: iy vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0017\n",
      "\n",
      "Pair: dcl vs aa\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0216\n",
      "\n",
      "Pair: dcl vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.0000\n",
      "\n",
      "Pair: aa vs ao\n",
      "Train Error: 0.0000\n",
      "Test Error: 0.3394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "model_qda = qda.fit(X_train, y_train)\n",
    "\n",
    "# train error\n",
    "pred_train=model_qda.predict(X_train)\n",
    "print(classification_report(y_train, pred_train))\n",
    "print(\"Train error \", (1-np.mean(pred_train == y_train)))\n",
    "\n",
    "print(\"\\n\")\n",
    "# test error\n",
    "pred_test=model_qda.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"Test Error \", (1-np.mean(pred_test == y_test)))\n",
    "print()\n",
    "\n",
    "phonemes = data['g'].unique()\n",
    "\n",
    "for i in range(len(phonemes)):\n",
    "    for j in range(i + 1, len(phonemes)):\n",
    "        phoneme_1 = phonemes[i]\n",
    "        phoneme_2 = phonemes[j]\n",
    "\n",
    "        # Corresponding data points for the pair of phonemes\n",
    "        selected_indices = (data['g'] == phoneme_1) | (data['g'] == phoneme_2)\n",
    "        selected_data = data[selected_indices]\n",
    "        \n",
    "        train_selected_data = selected_data.loc[selected_data.speaker.str.contains(\"train\")]\n",
    "        test_selected_data = selected_data.loc[selected_data.speaker.str.contains(\"test\")]\n",
    "        \n",
    "        X_train_selected = train_selected_data.drop(columns=['row.names', 'speaker', 'g'])\n",
    "        y_train_selected = train_selected_data['g']\n",
    "\n",
    "        X_test_selected = test_selected_data.drop(columns=['row.names', 'speaker', 'g'])\n",
    "        y_test_selected = test_selected_data['g']\n",
    "\n",
    "        # Fit qda model\n",
    "        qda_selected = QuadraticDiscriminantAnalysis()\n",
    "        qda_selected.fit(X_train_selected, y_train_selected)\n",
    "\n",
    "        train_pred_selected = qda_selected.predict(X_train_selected)\n",
    "        test_pred_selected = qda_selected.predict(X_test_selected)\n",
    "\n",
    "        train_error_sel = 1 - accuracy_score(y_train_selected, train_pred_selected)\n",
    "        test_error_sel = 1 - accuracy_score(y_test_selected, test_pred_selected)\n",
    "\n",
    "        print(f\"Pair: {phoneme_1} vs {phoneme_2}\")\n",
    "        #print(classification_report(y_train_selected, train_pred_selected))\n",
    "        print(f\"Train Error: {train_error_sel:.4f}\")\n",
    "        #print(classification_report(y_test_selected, test_pred_selected))\n",
    "        print(f\"Test Error: {test_error_sel:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3881746",
   "metadata": {},
   "source": [
    "Here, LDA is preferred, because it has a lower test error than QDA in both cases when trained with \n",
    "either all phonemes or with pair of phonemes. This indicates that LDA is better at generalizing. QDA \n",
    "models have a train error of 0, which is a strong indicative of overfitting, which explains why they \n",
    "perform less good on the test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d08a3",
   "metadata": {},
   "source": [
    "### 5. Confusion Matrices\n",
    "Generate confusion matrices for the LDA and QDA model for the combination of phenomes, which proved to be the hardest to classify. Which differences can you observe between the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "468e438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA for aa and ao\n",
      "train\n",
      "[[439  80]\n",
      " [ 56 703]] \n",
      "\n",
      "test\n",
      "[[121  55]\n",
      " [ 39 224]] \n",
      "\n",
      "\n",
      "\n",
      "QDA for aa and ao\n",
      "train\n",
      "[[519   0]\n",
      " [  0 759]] \n",
      "\n",
      "test\n",
      "[[ 29 147]\n",
      " [  2 261]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "boolList_train = y_train.str.contains('aa|ao')\n",
    "y_train_twoph = y_train[boolList_train]\n",
    "X_train_twoph = X_train[boolList_train]\n",
    "\n",
    "boolList_test = y_test.str.contains('aa|ao')\n",
    "y_test_twoph = y_test[boolList_test]\n",
    "X_test_twoph = X_test[boolList_test]\n",
    "\n",
    "#LDA\n",
    "print(\"LDA for aa and ao\")\n",
    "model_lda_twoph = lda.fit(X_train_twoph, y_train_twoph)\n",
    "\n",
    "#train\n",
    "print(\"train\")\n",
    "pred_train_lda_twoph = model_lda_twoph.predict(X_train_twoph)\n",
    "print(confusion_matrix(y_train_twoph, pred_train_lda_twoph), \"\\n\")\n",
    "#test\n",
    "print(\"test\")\n",
    "pred_test_lda_twoph = model_lda_twoph.predict(X_test_twoph)\n",
    "print(confusion_matrix(y_test_twoph, pred_test_lda_twoph), \"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#QDA\n",
    "print(\"QDA for aa and ao\")\n",
    "model_qda_twoph = qda.fit(X_train_twoph, y_train_twoph)\n",
    "\n",
    "#train\n",
    "print(\"train\")\n",
    "pred_train_qda_twoph = model_qda_twoph.predict(X_train_twoph)\n",
    "print(confusion_matrix(y_train_twoph, pred_train_qda_twoph), \"\\n\")\n",
    "#test\n",
    "print(\"test\")\n",
    "pred_test_qda_twoph = model_qda_twoph.predict(X_test_twoph)\n",
    "print(confusion_matrix(y_test_twoph, pred_test_qda_twoph), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea815f",
   "metadata": {},
   "source": [
    "We can see the confusion matrices shown above for LDA and QDA (train and test aa,ao phenome data). We can consider 1st column as \"aa\"-prediction and 2nd column as \"ao\"-prediction and 1st row as \"aa\"-actual and 2nd row as \"ao\"-actual. <br>\n",
    "We can observe that in train LDA, there is 439 correct predictions of \"aa\" and 703 correct predictions of \"ao\" while there are some wrong predictions also and similarly in test LDA, there is 121 correct predictions of \"aa\" and 224 correct prediciton of \"ao\" with some values of wrong prediction also.<br>\n",
    "In train QDA, there are all correct predictions and 0 wrong prediction. In test QDA, there are very few correct predicitons of \"aa\" and good number of prediction for \"ao\" while there are large number wrong predcitions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14608f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
